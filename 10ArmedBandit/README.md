# 10-Armed Bandit Test Bed

My own implementation of a few agents and bandit environment.

Later I might make the environment nonstationary and add an epsilon decaying agent.

![agents](Figures/Figure_1.png)

Here were the average reward at each step for 2000 runs with each agent.

The optimistic greedy agent unsurprisingly performed the best. When the problem becomes non-stationary, though.

